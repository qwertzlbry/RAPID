% hundepool2012sdc removed - use Hundepool2012 instead

@article{snoke2018utility,
  author  = {Snoke, Joshua and Raab, Gillian and Nowok, Beata and Dibben, Chris and Slavkovi{\'c}, Aleksandra},
  title   = {General and Specific Utility Measures for Synthetic Data},
  journal = {Journal of Privacy and Confidentiality},
  year    = {2018},
  volume  = {8},
  number  = {1}
}

@InProceedings{taub18,
author="Taub, Jennifer and Elliot, Mark and Pampaka, Maria and Smith, Duncan",
editor="Domingo-Ferrer, Josep
and Montes, Francisco",
title="Differential Correct Attribution Probability for Synthetic Data: An Exploration",
booktitle="Privacy in Statistical Databases",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="122--137",
abstract="Synthetic data generation has been proposed as a flexible alternative to more traditional statistical disclosure control (SDC) methods for limiting disclosure risk. Synthetic data generation is functionally distinct from standard SDC methods in that it breaks the link between the data subjects and the data such that reidentification is no longer meaningful. Therefore orthodox measures of disclosure risk assessment - which are based on reidentification - are not applicable. Research into developing disclosure assessment measures specifically for synthetic data has been relatively limited. In this paper, we develop a method called Differential Correct Attribution Probability (DCAP). Using DCAP, we explore the effect of multiple imputation on the disclosure risk of synthetic data.",
isbn="978-3-319-99771-1"
}

@article{reiter2019privacy,
  author  = {Reiter, Jerome P.},
  title   = {Privacy in Survey Data: A Review},
  journal = {Statistical Science},
  year    = {2019},
  volume  = {34},
  number  = {1},
  pages   = {40--53}
}

@manual{raab2024synthpop,
  author       = {Raab, Gillian M. and Nowok, Beata and Dibben, Chris and Snoke, Joshua},
  title        = {synthpop User Guide},
  year         = {2024},
  organization = {University of Edinburgh},
  note         = {R package vignette/manual; attribute disclosure tools incl.\ DiSCO},
  url          = {https://cran.r-project.org/package=synthpop}
}

@inproceedings{fredrikson2015model,
  author    = {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
  title     = {Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures},
  booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (CCS)},
  year      = {2015},
  pages     = {1322--1333},
  address   = {Denver, CO, USA},
  publisher = {ACM}
}

@inproceedings{shokri2017membership,
  author    = {Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  title     = {Membership Inference Attacks Against Machine Learning Models},
  booktitle = {2017 IEEE Symposium on Security and Privacy (SP)},
  year      = {2017},
  pages     = {3--18},
  address   = {San Jose, CA, USA},
  publisher = {IEEE}
}

@article{giomi2023unified,
  title   = {A Unified Framework for Quantifying Privacy Risk in Synthetic Data},
  author  = {Giomi, Matteo and Boenisch, Franziska and Wehmeyer, Christoph and Tasn{\'a}di, Borb{\'a}la},
  journal = {Proceedings on Privacy Enhancing Technologies},
  volume  = {2023},
  number  = {2},
  pages   = {312--328},
  year    = {2023},
  doi     = {10.56553/popets-2023-0055},
  url     = {https://petsymposium.org/popets/2023/popets-2023-0055.php}
}

@InProceedings{kwatra24,
author="Kwatra, Saloni
and Torra, Vicen{\c{c}}",
editor="Bieker, Felix
and de Conca, Silvia
and Gruschka, Nils
and Jensen, Meiko
and Schiering, Ina",
title="Empirical Evaluation of Synthetic Data Created by Generative Models via Attribute Inference Attack",
booktitle="Privacy and Identity Management. Sharing in a Digital World",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="282--291",
abstract="The disclosure risk of synthetic/artificial data is still being determined. Studies show that synthetic data generation techniques generate similar data to the original data and sometimes even the exact original data. Therefore, publishing synthetic datasets can endanger the privacy of users. In our work, we study the synthetic data generated from different synthetic data generation techniques, including the most recent diffusion models. We perform a disclosure risk assessment of synthetic datasets via an attribute inference attack, in which an attacker has access to a subset of publicly available features and at least one synthesized dataset, and the aim is to infer the sensitive features unknown to the attacker. We also compute the predictive accuracy and F1 score of the random forest classifier trained on several synthetic datasets. For sensitive categorical features, we show that Attribute Inference Attack is not highly feasible or successful. In contrast, for continuous attributes, we can have an approximate inference. This holds true for the synthetic datasets derived from Diffusion models, GANs, and DPGANs, which shows that we can only have approximated Attribute Inference, not the exact Attribute Inference.",
isbn="978-3-031-57978-3"
}

@misc{SNF_ORD2024,
  author       = {{Swiss National Science Fund (SNSF)}},
  title        = {{Open Research Data: ein erster Blick auf die aktuelle Praxis}},
  year         = {2024},
  howpublished = {\url{https://data.snf.ch/stories/open-research-data-2023-de.html}},
  note         = {accessed October 15, 2025},
}

@misc{ward25,
      title={Ensembling Membership Inference Attacks Against Tabular Generative Models},
      author={Ward, J. and Yang, Y. and Wang, C. and Cheng, G.},
      journal = {ArXiv},
      year={2025},
      archivePrefix={arXiv},
      url={https://doi.org/10.1145/3733799.3762977},
}


@Article{miletic24,
AUTHOR = {Miletic, Marko and Sariyar, Murat},
TITLE = {Challenges of Using Synthetic Data Generation Methods for Tabular Microdata},
JOURNAL = {Applied Sciences},
VOLUME = {14},
YEAR = {2024},
NUMBER = {14},
ARTICLE-NUMBER = {5975},
URL = {https://www.mdpi.com/2076-3417/14/14/5975},
ISSN = {2076-3417},
ABSTRACT = {The generation of synthetic data holds significant promise for augmenting limited datasets while avoiding privacy issues, facilitating research, and enhancing machine learning models’ robustness. Generative Adversarial Networks (GANs) stand out as promising tools, employing two neural networks—generator and discriminator—to produce synthetic data that mirrors real data distributions. This study evaluates GAN variants (CTGAN, CopulaGAN), a variational autoencoder, and copulas on diverse real datasets of different complexity encompassing numerical and categorical attributes. The results highlight CTGAN’s sensitivity to training parameters and TVAE’s robustness across datasets. Scalability challenges persist, with GANs demanding substantial computational resources. TVAE stands out for its high utility across all datasets, even for high-dimensional data, though it incurs higher privacy risks, which is indicative of the curse of dimensionality. While no single model universally excels, understanding the trade-offs and leveraging model strengths can significantly enhance synthetic data generation (SDG). Future research should focus on adaptive learning mechanisms, scalability enhancements, and standardized evaluation metrics to advance SDG methods effectively. Addressing these challenges will foster broader adoption and application of synthetic data.},
DOI = {10.3390/app14145975}
}


@misc{mekonnen24,
      title={Conditioning {GAN} Without Training Dataset},
      author={Kidist Amde Mekonnen},
      year={2024},
      eprint={2405.20687},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.20687},
}


@article{Thees25pca,
    author = {Thees, O. and M\"uller, R. and Templ, M.},
    title = {Beyond the Trade-off Curve: Multivariate and Advanced Risk-Utility Maps for Evaluating  Anonymized and Synthetic Data},
    journal = {Arxiv},
    year = {2025}
}

@article{simPop,
    author = {Templ, M. and Meindl, B. and Kowarik, A. and Dupriez, O.},
    title = {Simulation of Synthetic Complex Data: The {R} Package sim{P}op},
    journal = {Journal of Statistical Software},
    year = {2017},
    volume = {79},
    number = {10},
    pages = {1--38},
    url = {http://dx.doi.org/10.18637/jss.v079.i10},
    doi = {10.18637/jss.v079.i10},
    keywords = {microdata, simulation, synthetic data, population data, R}
}

@article{Alfons_2011_EUSILC,
    author = {Alfons, Andreas and Kraft, Stefan and Templ, Matthias and Filzmoser, Peter},
    title = {Simulation of close-to-reality population data for household surveys with application to {EU-SILC}},
    journal = {Statistical Methods \& Applications},
    year = {2011},
    volume = {20},
    number = {3},
    pages = {383--407},
    doi = {10.1007/s10260-011-0163-2}
}

@article{ranger,
    author = {Wright, Marvin N. and Ziegler, Andreas},
    title = {ranger: A Fast Implementation of Random Forests for High Dimensional Data in {C++} and {R}},
    journal = {Journal of Statistical Software},
    year = {2017},
    volume = {77},
    number = {1},
    pages = {1--17},
    doi = {10.18637/jss.v077.i01}
}

@article{barrientos18,
author = {Andr{\'e}s F. Barrientos and Alexander Bolton and Tom Balmat and Jerome P. Reiter and John M. de Figueiredo and Ashwin Machanavajjhala and Yan Chen and Charley Kneifel and Mark DeLong},
title = {{Providing access to confidential research data through synthesis and verification: An application to data on employees of the U.S. federal government}},
volume = {12},
journal = {The Annals of Applied Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {1124 -- 1156},
keywords = {Disclosure, privacy, public, remote, synthetic},
year = {2018},
doi = {10.1214/18-AOAS1194}
}

@article{pilgram25,
title = {A consensus privacy metrics framework for synthetic data},
journal = {Patterns},
pages = {101320},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101320},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925001680},
author = {Lisa Pilgram and Fida Kamal Dankar and Jörg Drechsler and Mark Elliot and Josep Domingo-Ferrer and Paul Francis and Murat Kantarcioglu and Linglong Kong and Bradley Malin and Krishnamurty Muralidhar and Puja Myles and Fabian Prasser and Jean Louis Raisaro and Chao Yan and Khaled {El Emam}},
keywords = {synthetic data, privacy, generative artificial intelligence, membership disclosure, attribute disclosure, identity disclosure, data sharing},
abstract = {Summary
Synthetic data generation is a promising approach for sharing data for secondary purposes in sensitive sectors. However, to meet ethical standards and legislative requirements, it is necessary to demonstrate that the privacy of the individuals upon which the synthetic records are based is adequately protected. Through an expert consensus process, we developed a framework for privacy evaluation in synthetic data. The most commonly used metrics measure similarity between real and synthetic data and are assumed to capture identity disclosure. Our findings indicate that they lack precise interpretation and should be avoided. There was consensus on the importance of membership and attribute disclosure, both of which involve inferring personal information. The framework provides recommendations to effectively measure these types of disclosures, which also apply to differentially private synthetic data if the privacy budget is not close to zero. We further present future research opportunities to support widespread adoption of synthetic data.}
}

@misc{MuralidharRuggles2024,
  author       = {Muralidhar, K. and Ruggles, S.},
  title        = {Escalation of Commitment: A Case Study of the United States Census Bureau Efforts to Implement Differential Privacy for the 2020 Decennial Census},
  year         = {2024},
  eprint       = {2407.15957},
  archivePrefix= {arXiv},
  primaryClass = {cs.CR},
  doi          = {10.48550/arXiv.2407.15957},
  url          = {https://doi.org/10.48550/arXiv.2407.15957},
  note         = {arXiv preprint}
}

@article{BlancoJusticia2022,
  author    = {Blanco-Justicia, A. and S{\'a}nchez, D. and Domingo-Ferrer, J. and Muralidhar, K.},
  title     = {A Critical Review on the Use (and Misuse) of Differential Privacy in Machine Learning},
  journal   = {ACM Computing Surveys},
  volume    = {55},
  number    = {8},
  pages     = {Article 160, 1--16},
  year      = {2022},
  doi       = {10.1145/3547139},
  publisher = {ACM},
  url       = {https://doi.org/10.1145/3547139}
}

@article{domingo21,
author = {Domingo-Ferrer, Josep and S\'{a}nchez, David and Blanco-Justicia, Alberto},
title = {The limits of differential privacy (and its misuse in data release and machine learning)},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/3433638},
doi = {10.1145/3433638},
abstract = {Differential privacy is not a silver bullet for all privacy problems.},
journal = {Commun. ACM},
month = jun,
pages = {33–35},
numpages = {3}
}

@article{muralidhar23,
author = {Krishnamurty Muralidhar and Josep Domingo-Ferrer},
title ={Database Reconstruction Is Not So Easy and Is Different from Reidentification},
journal = {Journal of Official Statistics},
volume = {39},
number = {3},
pages = {381-398},
year = {2023},
doi = {10.2478/jos-2023-0017}
}

@misc{francis2025betterattributeinferencevulnerability,
      title={Towards Better Attribute Inference Vulnerability Measures},
      author={Paul Francis and David Wagner},
      year={2025},
      eprint={2507.01710},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2507.01710},
}


@techreport{Duncan01a,
	Author = {Duncan, G.T. and Keller-McNulty, S.A. and Stokes, S.L.},
	Institution = {Los Alamos National Laboratory},
	Title = {Disclosure risk vs. data utility: the R-U confidentiality map},
	Type = {Technical Report LA-UR-01-6428},
	Url = {http://www.heinz.cmu.edu/research/122full.pdf},
	Year = {2001},
	Bdsk-Url-1 = {http://www.heinz.cmu.edu/research/122full.pdf}}

@article{PlatzerReutterer2021Holdout,
  author  = {Platzer, M. and Reutterer, T.},
  title   = {Holdout-Based Empirical Assessment of Mixed-Type Synthetic Data},
  journal = {Frontiers in Big Data},
  year    = {2021},
  volume  = {4},
  pages   = {679939},
  doi     = {10.3389/fdata.2021.679939},
  url     = {https://doi.org/10.3389/fdata.2021.679939}
}

@inproceedings{hittmeir20,
author = {Hittmeir, Markus and Mayer, Rudolf and Ekelhart, Andreas},
title = {A Baseline for Attribute Disclosure Risk in Synthetic Data},
year = {2020},
isbn = {9781450371070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3374664.3375722},
abstract = {The generation of synthetic data is widely considered as viable method for alleviating privacy concerns and for reducing identification and attribute disclosure risk in micro-data. The records in a synthetic dataset are artificially created and thus do not directly relate to individuals in the original data in terms of a 1-to-1 correspondence. As a result, inferences about said individuals appear to be infeasible and, simultaneously, the utility of the data may be kept at a high level. In this paper, we challenge this belief by interpreting the standard attacker model for attribute disclosure as classification problem. We show how disclosure risk measures presented in recent publications may be compared to or even be reformulated as machine learning classification models. Our overall goal is to empirically analyze attribute disclosure risk in synthetic data and to discuss its close relationship to data utility. Moreover, we improve the baseline for attribute disclosure risk from the attacker's perspective by applying variants of the RadiusNearestNeighbor and the EnsembleVote classifier.},
booktitle = {Proceedings of the Tenth ACM Conference on Data and Application Security and Privacy},
pages = {133–143},
numpages = {11},
keywords = {machine learning, privacy-preserving data mining, synthetic data},
location = {New Orleans, LA, USA},
series = {CODASPY '20}
}

@article{templ14risk,
title = {Providing Data with High Utility and no Disclosure Risk for the Public and Researchers: An Evaluation by Advanced Statistical Disclosure Risk},
volume={43},
author = {Templ, M.},
DOI={10.17713/ajs.v43i4.43},
number={4},
year = {2014},
journal={Austrian Journal of Statistics},
pages={247–254}
}

@article{emam20,
  author    = {El Emam, Khaled and Mosquera, Laura and Bass, Jason},
  title     = {Evaluating Identity Disclosure Risk in Fully Synthetic Health Data: Model Development and Validation},
  journal   = {Journal of Medical Internet Research},
  year      = {2020},
  volume    = {22},
  number    = {11},
  pages     = {e23139},
  doi       = {10.2196/23139},
  pmid      = {33196453},
  pmcid     = {PMC7704280},
  url       = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7704280/}
}


@book{sdcMicroBook,
  title={Statistical Disclosure Control for Microdata: Methods and Applications in {R}},
  author={Templ, M.},
  isbn={9783319502724},
  year={2017},
  publisher={Springer International Publishing},
  address={Cham, Switzerland}
}


@inproceedings{Stadler20c,
  title={Synthetic Data - Anonymisation Groundhog Day},
  author={Theresa Stadler and Bristena Oprisanu and Carmela Troncoso},
  booktitle={USENIX Security Symposium},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:235391080}
}

@book{Hundepool2012,
  author = {Hundepool, Anco and Domingo-Ferrer, Josep and Franconi, Luisa and Giessing, Sarah and Schulte Nordholt, Eric and Spicer, Keith and de Wolf, Patrick},
  title = {Statistical Disclosure Control},
  publisher = {Wiley},
  year = {2012},
  address = {Chichester, UK}
}

@article{Rubin93,
	Author = {Rubin, D.B.},
	Journal = {Journal of Official Statistics},
	Number = {2},
	Pages = {461--468},
	Title = {Discussion of statistical disclosure limitation.},
	Volume = {9},
	Year = {1993}}

@InProceedings{thees24,
author="Thees, Oscar
and Nov{\'a}k, Ji{\v{r}}{\'i}
and Templ, Matthias",
editor="Domingo-Ferrer, Josep
and {\"O}nen, Melek",
title="Evaluation of Synthetic Data Generators on Complex Tabular Data",
booktitle="Privacy in Statistical Databases",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="194--209"
}


@book{duncan11,
  title={Statistical Confidentiality: Principles and Practice},
  author={Duncan, G.T. and Elliot, M. and Salazar, G.J.J.},
  isbn={9781441978011},
  lccn={2011275372},
  series={Statistics for Social and Behavioral Sciences},
  year={2011},
  publisher={Springer New York}
}

@article{Machanava07,
 author = {Machanavajjhala, A. and Kifer, D. and Gehrke, J. and Venkitasubramaniam, M.},
 title = {$l$-diversity: Privacy beyond $k$-anonymity},
 journal = {ACM Trans. Knowl. Discov. Data},
 issue_date = {March 2007},
 volume = {1},
 number = {1},
 month = mar,
 year = {2007},
 issn = {1556-4681},
 articleno = {3},
 doi = {10.1145/1217299.1217302},
 acmid = {1217302},
 publisher = {ACM},
 address = {New York, NY, USA}
}

@techreport{Samarati98,
	Author = {Samarati, P. and Sweeney, L.},
	Institution = {SRI International},
	Number = {SRI-CSL-98-04},
	Title = {Protecting privacy when disclosing information: \emph{k}-anonymity and its enforcement through generalization and suppression},
	Year = {1998}}

@misc{drechsler202330yearssyntheticdata,
      title={30 Years of Synthetic Data},
      author={Joerg Drechsler and Anna-Carolina Haensch},
      year={2023},
      eprint={2304.02107},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2304.02107}
}


@article{DomingoFerrer_2025_Statistical,
  title = {Statistical {{Disclosure Control}}: {{Moving Forward}}},
  shorttitle = {Statistical {{Disclosure Control}}},
  author = {{Domingo-Ferrer}, Josep and S{\'a}nchez, David and Muralidhar, Krishnamurty},
  year = 2025,
  month = sep,
  journal = {Journal of Official Statistics},
  volume = {41},
  number = {3},
  pages = {820--826},
  issn = {0282-423X, 2001-7367},
  doi = {10.1177/0282423X241312023},
  urldate = {2025-11-20},
  copyright = {https://creativecommons.org/licenses/by-nc/4.0/},
  langid = {english},
  file = {/Users/oscar.thees@fhnw.ch/Zotero/storage/HNCCHPQH/Domingo-Ferrer et al. - 2025 - Statistical Disclosure Control Moving Forward.pdf}
}

@article{DomingoFerrer_2025_Privacy,
  title = {Do {{Privacy Models Deliver}}?},
  author = {{Domingo-Ferrer}, Josep and S{\'a}nchez, David and Blanco-Justicia, Alberto},
  year = {2025},
  journal = {arXiv preprint},
  eprint = {2510.11299},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR},
  url = {https://arxiv.org/abs/2510.11299},
  note = {Argues that DP incurs unacceptable utility loss for small privacy budgets, while its guarantee becomes meaningless for large budgets}
}

@article{Duncan_1989_Risk,
  title = {The {{Risk}} of {{Disclosure}} for {{Microdata}}},
  author = {Duncan, George and Lambert, Diane},
  year = 1989,
  journal = {Journal of Business \& Economic Statistics},
  volume = {7},
  number = {2},
  pages = {207--217},
  doi = {10.2307/1391438},
  langid = {english},
  file = {/Users/oscar.thees@fhnw.ch/Zotero/storage/G3926WFN/Duncan - The Risk of Disclosure for Microdata.pdf}
}
@article{Palley_1987_Use,
  title = {The Use of Regression Methodology for the Compromise of Confidential Information in Statistical Databases},
  author = {Palley, Michael A. and Simonoff, Jeffrey S.},
  year = 1987,
  month = nov,
  journal = {ACM Transactions on Database Systems},
  volume = {12},
  number = {4},
  pages = {593--608},
  issn = {0362-5915, 1557-4644},
  doi = {10.1145/32204.42174},
  urldate = {2025-12-02},
  abstract = {A regression methodology based technique can be used to compromise confidentiality in a statistical database. This holds true even when the DBMS prevents application of regression methodology to the database. Existing inference controls, including cell restriction, perturbation, and table restriction approaches, are shown to be generally ineffective against this compromise technique. The effect of incomplete supplemental knowledge on the regression methodology based compromise technique is examined. Finally, some potential complicators of this disclosure scheme are introduced.},
  langid = {english},
  file = {/Users/oscar.thees@fhnw.ch/Zotero/storage/KKYKJ53G/Palley and Simonoff - 1987 - The use of regression methodology for the compromise of confidential information in statistical data.pdf}
}
@article{Dalenius_1977_Methodology,
  title = {Towards a Methodology for Statistical Disclosure Control},
  author = {Dalenius, Tore},
  year = 1977,
  journal = {Statistisk tidskrift},
  volume = {15},
  pages = {429--444},
  file = {/Users/oscar.thees@fhnw.ch/Zotero/storage/SXYTAAM6/dalenius-1977.pdf}
}

@article{2015_Nosek,
	title = {Promoting an open research culture},
	volume = {348},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4550299/},
	doi = {10.1126/science.aab2374},
	pages = {1422--1425},
	number = {6242},
	journaltitle = {Science (New York, N.Y.)},
	journal = {Science},
	author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and {McNutt}, M. and Miguel, E. and Levy Paluck, E. and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and {VandenBos}, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
	year = {2015},
	pmid = {26113702},
	pmcid = {PMC4550299},
}

@article{Munch_2021_Privacy,
  title = {Privacy Rights and `Naked' Statistical Evidence},
  author = {Munch, Lauritz Aastrup},
  year = 2021,
  month = nov,
  journal = {Philosophical Studies},
  volume = {178},
  number = {11},
  pages = {3777--3795},
  issn = {0031-8116, 1573-0883},
  doi = {10.1007/s11098-021-01625-0},
  urldate = {2025-12-16},
  abstract = {Do privacy rights restrict what is permissible to infer about others based on statistical evidence? This paper replies affirmatively by defending the following symmetry: there is not necessarily a morally relevant difference between directly appropriating people's private information---say, by using an X-ray device on their private safes---and using predictive technologies to infer the same content, at least in cases where the evidence has a roughly similar probative value. This conclusion is of theoretical interest because a comprehensive justification of the thought that statistical inferences can violate privacy rights is lacking in the current literature. Secondly, the conclusion is of practical interest due to the need for moral assessment of emerging predictive algorithms.},
  langid = {english},
  file = {/Users/oscar.thees@fhnw.ch/Zotero/storage/6SMEGH7D/Munch - 2021 - Privacy rights and ‘naked’ statistical evidence.pdf}
}
@article{Muhlhoff_2021_Predictive,
  title = {Predictive Privacy: Towards an Applied Ethics of Data Analytics},
  shorttitle = {Predictive Privacy},
  author = {M{\"u}hlhoff, Rainer},
  year = 2021,
  month = dec,
  journal = {Ethics and Information Technology},
  volume = {23},
  number = {4},
  pages = {675--690},
  issn = {1388-1957, 1572-8439},
  doi = {10.1007/s10676-021-09606-x},
  urldate = {2026-01-13},
  abstract = {Data analytics and data-driven approaches in Machine Learning are now among the most hailed computing technologies in many industrial domains. One major application is predictive analytics, which is used to predict sensitive attributes, future behavior, or cost, risk and utility functions associated with target groups or individuals based on large sets of behavioral and usage data. This paper stresses the severe ethical and data protection implications of predictive analytics if it is used to predict sensitive information about single individuals or treat individuals differently based on the data many unrelated individuals provided. To tackle these concerns in an applied ethics, first, the paper introduces the concept of ``predictive privacy'' to formulate an ethical principle protecting individuals and groups against differential treatment based on Machine Learning and Big Data analytics. Secondly, it analyses the typical data processing cycle of predictive systems to provide a step-by-step discussion of ethical implications, locating occurrences of predictive privacy violations. Thirdly, the paper sheds light on what is qualitatively new in the way predictive analytics challenges ethical principles such as human dignity and the (liberal) notion of individual privacy. These new challenges arise when predictive systems transform statistical inferences, which provide knowledge about the cohort of training data donors, into individual predictions, thereby crossing what I call the ``prediction gap''. Finally, the paper summarizes that data protection in the age of predictive analytics is a collective matter as we face situations where an individual's (or group's) privacy is violated using data other individuals provide about themselves, possibly even anonymously.},
  langid = {english},
  file = {/Users/oscar.thees@fhnw.ch/Zotero/storage/D3WCCCFK/Mühlhoff - 2021 - Predictive privacy towards an applied ethics of data analytics.pdf}
}
@inproceedings{Latner_2025_Buyer,
  title = {Buyer {{Beware}}: {{Understanding}} the Trade-off between Utility and Risk in {{CART}} Based Models Using Simulation Data},
  shorttitle = {Conference of {{European Statisticians}}},
  booktitle = {{{UNECE Expert Meeting}} on {{Statistical Data Confidentiality}}},
  author = {Latner, Jonathan and Neunhoeffer, Marcel and Drechsler, J{\"o}rg},
  year = 2025,
  pages = {1--12},
  publisher = {United Nations},
  address = {Barcelona},
  doi = {10.18356/9789210010795},
  urldate = {2026-01-13},
  abstract = {This paper evaluates disclosure risk measures for synthetic data generated by CART-based models, using both a controlled simulated dataset and publicly available data. We find that common disclosure risk measures may fail to detect disclosure risks and, in some cases, misrepresent actual disclosure risks. Additionally, CART-based models, while maintaining high statistical utility, may compromise privacy protection. Our findings highlight challenges in measuring disclosure risk of synthetic data and suggest improvements for more accurate risk assessments.},
  isbn = {978-92-1-001079-5},
  langid = {english},
  file = {/Users/oscar.thees@fhnw.ch/Zotero/storage/7MCUEGQV/United Nations Economic Commission for Europe - 2022 - Conference of European Statisticians Road Map on Statistics for Sustainable Development Goals - Sec.pdf}
}

@article{Dwork_2010_Difficulties,
  title = {On the Difficulties of Disclosure Prevention in Statistical Databases or the Case for Differential Privacy},
  author = {Dwork, Cynthia and Naor, Moni},
  year = 2010,
  month = sep,
  journal = {Journal of Privacy and Confidentiality},
  volume = {2},
  number = {1},
  pages = {93--107},
  issn = {2575-8527},
  doi = {10.29012/jpc.v2i1.585},
  urldate = {2025-12-16},
  langid = {english},
  keywords = {validated}
}

@article{Reiter_2014_Bayesiana,
  title = {Bayesian {{Estimation}} of {{Disclosure Risks}} for {{Multiply Imputed}}, {{Synthetic Data}}},
  author = {Reiter, Jerome P. and Wang, Quanli and Zhang, Biyuan},
  year = 2014,
  month = jun,
  journal = {Journal of Privacy and Confidentiality},
  volume = {6},
  number = {1},
  issn = {2575-8527},
  doi = {10.29012/jpc.v6i1.635},
  urldate = {2026-01-14},
  abstract = {Agencies seeking to disseminate public use microdata, i.e., data on individual records, can replace confidential values with multiple draws from statistical models estimated with the collected data. We present a famework for evaluating disclosure risks inherent in releasing multiply-imputed, synthetic data. The basic idea is to mimic an intruder who computes posterior distributions of confidential values given the released synthetic data and prior knowledge. We illustrate the methodology with artificial fully synthetic data and with partial synthesis of the Survey of Youth in Custody.},
  copyright = {http://creativecommons.org/licenses/by-sa/4.0},
  langid = {english},
  file = {/Users/oscar.thees@fhnw.ch/Zotero/storage/V2J85N65/Reiter et al. - 2014 - Bayesian Estimation of Disclosure Risks for Multiply Imputed, Synthetic Data.pdf}
}
@misc{adult_2,
  author       = {Becker, Barry and Kohavi, Ronny},
  title        = {{Adult}},
  year         = {1996},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5XW20}
}

@book{Willenborg_2001_Elements,
	location = {New York, {NY}, {USA}},
	edition = {1},
	title = {Elements of statistical disclosure control},
	volume = {155},
	rights = {http://www.springer.com/tdm},
	isbn = {978-1-4613-0121-9},
	url = {http://link.springer.com/10.1007/978-1-4613-0121-9},
	series = {Lecture Notes in Statistics},
	pagetotal = {261},
	publisher = {Springer},
	author = {Willenborg, Leon and de Waal, Ton},
	editorb = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S.},
	editorbtype = {redactor},
	urldate = {2025-03-14},
	year = {2001},
	langid = {english},
	doi = {10.1007/978-1-4613-0121-9}
}

@inproceedings{Machanavajjhala_2006_Ldiversity,
	location = {New York, {NY}, {USA}},
	title = {L-diversity: privacy beyond k-anonymity},
	isbn = {0-7695-2570-9},
	url = {https://ieeexplore.ieee.org/document/1617392},
	doi = {10.1109/ICDE.2006.1},
	shorttitle = {L-diversity},
	abstract = {Publishing data about individuals without revealing sensitive information about them is an important problem. In recent years, a new definition of privacy called {\textbackslash}kappa-anonymity has gained popularity. In a {\textbackslash}kappa-anonymized dataset, each record is indistinguishable from at least k—1 other records with respect to certain "identifying" attributes. In this paper we show with two simple attacks that a {\textbackslash}kappa-anonymized dataset has some subtle, but severe privacy problems. First, we show that an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. Second, attackers often have background knowledge, and we show that {\textbackslash}kappa-anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks and we propose a novel and powerful privacy definition called {\textbackslash}ell-diversity. In addition to building a formal foundation for {\textbackslash}ell-diversity, we show in an experimental evaluation that {\textbackslash}ell-diversity is practical and can be implemented efficiently.},
	eventtitle = {{ICDE}'06, Atlanta, {GA}, {USA}},
	pages = {24},
	booktitle = {22nd International Conference on Data Engineering ({ICDE}'06)},
	publisher = {{IEEE}: Institute of Electrical and Electronics Engineers},
	author = {Machanavajjhala, Ashwin and Gehrke, Johannes and Kifer, Daniel and Venkitasubramaniam, Muthuramakrishnan},
	urldate = {2025-03-08},
	year = {2006},
	langid = {english},
	note = {{ISSN}: 2375-026X}
}

@article{Cao_2012_Publishing,
	title = {Publishing microdata with a robust privacy guarantee},
	volume = {5},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/2350229.2350255},
	doi = {10.14778/2350229.2350255},
	abstract = {Today, the publication of microdata poses a privacy threat. Vast research has striven to define the privacy condition that microdata should satisfy before it is released, and devise algorithms to anonymize the data so as to achieve this condition. Yet, no method proposed to date explicitly bounds the percentage of information an adversary gains after seeing the published data for each sensitive value therein. This paper introduces β-likeness, an appropriately robust privacy model for microdata anonymization, along with two anonymization schemes designed therefore, the one based on generalization, and the other based on perturbation. Our model postulates that an adversary's confidence on the likelihood of a certain sensitive-attribute ({SA}) value should not increase, in relative difference terms, by more than a predefined threshold. Our techniques aim to satisfy a given β threshold with little information loss. We experimentally demonstrate that (i) our model provides an effective privacy guarantee in a way that predecessor models cannot, (ii) our generalization scheme is more effective and efficient in its task than methods adapting algorithms for the k-anonymity model, and (iii) our perturbation method outperforms a baseline approach. Moreover, we discuss in detail the resistance of our model and methods to attacks proposed in previous research.},
	pages = {1388--1399},
	number = {11},
	journaltitle = {Proceedings of the {VLDB} Endowment},
	shortjournal = {{PVLDB}},
	author = {Cao, Jianneng and Karras, Panagiotis},
	urldate = {2025-03-15},
	year = {2012},
	langid = {english}
}

@inproceedings{Taub_2019_Creating,
	location = {The Hague, Netherlands},
	title = {Creating the best risk-utility profile: The synthetic data challenge},
	url = {https://unece.org/sites/default/files/datastore/fileadmin/DAM/stats/documents/ece/ces/ge.46/2019/mtg1/SDC2019_S3_UK_Synthethic_Data_Challenge_Elliot_AD.pdf},
	shorttitle = {The synthetic data challenge},
	abstract = {Data synthesis is an alternative to traditional statistical disclosure control ({SDC}) methods or access restrictions for controlling the conﬁdentiality risk arising from data sharing. There are several diﬀerent techniques used to produce synthetic data; the goal of all of them is to produce useful data with very low disclosure risk. An important and current research goal is the development of credible measures of both the risk and utility of synthetic data. Without such credible measures, it is diﬃcult for either analysts or data owners to trust synthetic data or to know which data synthesis methods work best (for their data). As part of the Isaac Newton Institute programme on Data Linkage and Anonymisation in 2016, we ran a challenge to test various synthetic data generation methods against one another. Four diﬀerent research teams produced eight synthetic versions of the same dataset using diﬀerent synthetic data production methods. The synthetic datasets were then put through a battery of tests for both data utility and disclosure risk. The challenge study has produced signiﬁcant insights not only about the synthetic data generation techniques, but also about the eﬀectiveness of diﬀerent measures designed to capture the utility/risk characteristics of synthetic data.},
	eventtitle = {Conference of European Statisticians},
	pages = {1--21},
	booktitle = {Joint {UNECE}/Eurostat Work Session on Statistical Data Confidentiality},
	publisher = {{UNECE}},
	author = {Taub, Jennifer and Elliot, M. J. and Raab, G. M. and Charest, Anne-Sophie and Chen, Cong and O’Keefe, Christine M. and Nixon, Michelle Pistner and Snoke, Joshua and Slavković, Aleksandra},
	year = {2019},
	langid = {english}
}

@misc{Raab_2025_Practical,
	title = {Practical privacy metrics for synthetic data},
	url = {http://arxiv.org/abs/2406.16826},
	doi = {10.48550/arXiv.2406.16826},
	abstract = {This paper explains how the synthpop package for R has been extended to include functions to calculate measures of identity and attribute disclosure risk for synthetic data that measure risks for the records used to create the synthetic data. The basic function, disclosure, calculates identity disclosure for a set of quasi-identifiers (keys) and attribute disclosure for one variable specified as a target from the same set of keys. The second function, disclosure.summary, is a wrapper for the first and presents summary results for a set of targets. This short paper explains the measures of disclosure risk and documents how they are calculated. We recommend two measures: \${RepU}\$ (replicated uniques) for identity disclosure and \${DiSCO}\$ (Disclosive in Synthetic Correct Original) for attribute disclosure. Both are expressed a {\textbackslash}\% of the original records and each can be compared to similar measures calculated from the original data. Experience with using the functions on real data found that some apparent disclosures could be identified as coming from relationships in the data that would be expected to be known to anyone familiar with its features. We flag cases when this seems to have occurred and provide means of excluding them.},
	number = {{arXiv}:2406.16826},
	publisher = {{arXiv}},
	author = {Raab, G. M. and Nowok, Beata and Dibben, Chris},
	urldate = {2025-08-25},
	year = {2025},
	langid = {english},
	note = {Pages: 1-23}
}

@article{Nowok_2016_Synthpop,
	title = {synthpop: Bespoke creation of synthetic data in R},
	volume = {74},
	issn = {1548-7660},
	url = {https://doi.org/10.18637/jss.v074.i11},
	doi = {10.18637/jss.v074.i11},
	shorttitle = {synthpop},
	abstract = {In many contexts, confidentiality constraints severely restrict access to unique and valuable microdata. Synthetic data which mimic the original observed data and preserve the relationships between variables but do not contain any disclosive records are one possible solution to this problem. The synthpop package for R, introduced in this paper, provides routines to generate synthetic versions of original data sets. We describe the methodology and its consequences for the data characteristics. We illustrate the package features using a survey data example.},
	pages = {1--26},
	number = {11},
	journaltitle = {Journal of Statistical Software},
	shortjournal = {{JSS}},
	author = {Nowok, Beata and Raab, G. M. and Dibben, Chris},
	urldate = {2025-05-23},
	year = {2016},
	langid = {english}
}

@article{wilson1927probable,
	title = {Probable inference, the law of succession, and statistical inference},
	author = {Wilson, Edwin B.},
	journal = {Journal of the American Statistical Association},
	volume = {22},
	number = {158},
	pages = {209--212},
	year = {1927},
	publisher = {Taylor \& Francis}
}

@article{clopper1934use,
	title = {The use of confidence or fiducial limits illustrated in the case of the binomial},
	author = {Clopper, Charles J. and Pearson, Egon S.},
	journal = {Biometrika},
	volume = {26},
	number = {4},
	pages = {404--413},
	year = {1934},
	publisher = {Oxford University Press}
}

@Manual{xgboost,
	title = {xgboost: Extreme Gradient Boosting},
	author = {Tianqi Chen and Tong He and Michael Benesty and Vadim Khotilovich and Yuan Tang and Hyunsu Cho and Kailong Chen and Rory Mitchell and Ignacio Cano and Tianyi Zhou and Mu Li and Junyuan Xie and Min Lin and Yifeng Geng and Yutian Li and Jiaming Yuan and David Cortes},
	year = {2025},
	note = {R package version 3.1.2.1},
	url = {https://CRAN.R-project.org/package=xgboost},
	doi = {10.32614/CRAN.package.xgboost}
}

@article{Hu_2021_Bayesian,
	title = {Bayesian Estimation of Attribute and Identification Disclosure Risks in Synthetic Data},
	author = {Hu, Jingchen},
	year = {2021},
	journal = {Transactions on Data Privacy},
	volume = {14},
	number = {1},
	pages = {61--89}
}
